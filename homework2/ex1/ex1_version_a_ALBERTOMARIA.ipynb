{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex1_version_a_marco.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngaEP8_bL3YF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf9368f-3fbc-4dea-bd1f-a83d116975d5"
      },
      "source": [
        "!rm -r models\n",
        "!rm -r tflite_models/\n",
        "!rm -r weight_only_PTQ_models/\n",
        "!rm -r pruned_models/\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'tflite_models/': No such file or directory\n",
            "rm: cannot remove 'weight_only_PTQ_models/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIPWAWdxdq7q",
        "outputId": "02fa752f-70df-4d28-d93e-98e30078e649"
      },
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import zlib\n",
        "\n",
        "\"\"\"\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model', type=str, required=True, help='model name')\n",
        "parser.add_argument('--labels', type=int, required=True, help='model output')\n",
        "args = parser.parse_args()\"\"\"\n",
        "\n",
        "\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True,\n",
        "    cache_dir='.', cache_subdir='data')\n",
        "csv_path, _ = os.path.splitext(zip_path)\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "column_indices = [2, 5]\n",
        "columns = df.columns[column_indices]\n",
        "data = df[columns].values.astype(np.float32)\n",
        "\n",
        "n = len(data)\n",
        "train_data = data[0:int(n*0.7)]\n",
        "val_data = data[int(n*0.7):int(n*0.9)]\n",
        "test_data = data[int(n*0.9):]\n",
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "\n",
        "input_width = 12 \n",
        "\n",
        "\n",
        "class WindowGenerator:\n",
        "    def __init__(self, input_width, mean, std):\n",
        "        self.input_width = input_width \n",
        "        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])\n",
        "        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\n",
        "\n",
        "    def split_window(self, features):\n",
        "        \n",
        "        inputs = features[:, :6, :]\n",
        "        labels = features[:, -6:, :]\n",
        "        inputs.set_shape([None, 6, 2])\n",
        "        labels.set_shape([None, 6, 2])\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def normalize(self, features):\n",
        "        features = (features - self.mean) / (self.std + 1.e-6)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def preprocess(self, features):\n",
        "        inputs, labels = self.split_window(features)\n",
        "        inputs = self.normalize(inputs)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def make_dataset(self, data, train):\n",
        "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "                data=data,\n",
        "                targets=None,\n",
        "                sequence_length=12,\n",
        "                sequence_stride=1,\n",
        "                batch_size=512)\n",
        "        \n",
        "        \n",
        "        ds = ds.map(self.preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        ds = ds.cache()\n",
        "        if train is True:\n",
        "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
        "\n",
        "        return ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "generator = WindowGenerator(input_width, mean, std)\n",
        "train_ds = generator.make_dataset(train_data, True)\n",
        "val_ds = generator.make_dataset(val_data, False)\n",
        "test_ds = generator.make_dataset(test_data, False)\n",
        "\n",
        "for x, y in train_ds:\n",
        "    input_shape = x.shape.as_list()[1:]\n",
        "    output_shape = y.shape.as_list()[1:]\n",
        "    break\n",
        "\n",
        "print(f'Input shape: {input_shape}')\n",
        "print(f'Output shape: {output_shape}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (0.1.5)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.15.0)\n",
            "Input shape: [6, 2]\n",
            "Output shape: [6, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmZQxk3wd_Nq"
      },
      "source": [
        "class MyModel:\n",
        "    def __init__(self, model_name, alpha, input_shape, output_shape, final_sparsity=None):\n",
        "        \n",
        "        if model_name.lower() == 'mlp':\n",
        "            # create the mlp model\n",
        "            model = tf.keras.Sequential([\n",
        "                tf.keras.layers.Flatten(input_shape=input_shape, name='flatten'),\n",
        "                tf.keras.layers.Dense(int(alpha*128), activation='relu', name='first_dense'),\n",
        "                tf.keras.layers.Dense(12, name='third_dense'),\n",
        "                tf.keras.layers.Reshape(output_shape)\n",
        "\n",
        "            ])\n",
        "\n",
        "        elif model_name.lower() == 'cnn':\n",
        "            # create the cnn model\n",
        "            model = tf.keras.Sequential([\n",
        "                tf.keras.layers.Conv1D(input_shape = input_shape, filters=int(64*alpha), kernel_size=3, activation='relu', name='1_conv1d'),\n",
        "                tf.keras.layers.Conv1D(input_shape = input_shape, filters=int(64*alpha), kernel_size=3, activation='relu', name='2_conv1d'),\n",
        "                tf.keras.layers.Flatten(),\n",
        "                tf.keras.layers.Dense(int(alpha*64), activation='relu', name='first_dense'),\n",
        "                tf.keras.layers.Dense(12, name='second_dense'),\n",
        "                tf.keras.layers.Reshape(output_shape)\n",
        "            ])\n",
        "        \n",
        "        model.summary()\n",
        "        self.model = model\n",
        "        self.alpha = alpha\n",
        "        self.final_sparsity = final_sparsity\n",
        "        self.model_name = model_name.lower()\n",
        "        if alpha != 1:\n",
        "            self.model_name += '_ws' + str(alpha).split('.')[1]\n",
        "        if final_sparsity is not None and 'lstm' not in self.model_name :\n",
        "            self.model_name += '_mb' + str(final_sparsity).split('.')[1]\n",
        "            self.magnitude_pruning = True\n",
        "        else:\n",
        "            self.magnitude_pruning = False\n",
        "        \n",
        "        self.final_sparsity = final_sparsity\n",
        "        #print(self.magnitude_pruning)\n",
        "\n",
        "    def compile_model(self, optimizer, loss_function, eval_metric):\n",
        "\n",
        "        if self.magnitude_pruning:\n",
        "            #sparsity scheduler\n",
        "            pruning_params = {\n",
        "                'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay( \n",
        "                                                                initial_sparsity=0.30,\n",
        "                                                                final_sparsity=self.final_sparsity,\n",
        "                                                                begin_step=len(train_ds)*5,\n",
        "                                                                end_step=len(train_ds)*15)\n",
        "            }\n",
        "\n",
        "            prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "            self.model = prune_low_magnitude(self.model, **pruning_params)\n",
        "\n",
        "            input_shape = [32, 6, 2]\n",
        "            self.model.build(input_shape)\n",
        "\n",
        "        self.model.compile(\n",
        "            optimizer = optimizer,\n",
        "            loss = loss_function,\n",
        "            metrics = eval_metric\n",
        "        )\n",
        "\n",
        "\n",
        "        \n",
        "    def train_model(self,X_train, X_val, N_EPOCH, callbacks=[]):\n",
        "        \n",
        "        if self.magnitude_pruning:\n",
        "            callbacks.append(tfmot.sparsity.keras.UpdatePruningStep())\n",
        "\n",
        "        print('\\tTraining... ')\n",
        "        print('\\t', end='')\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X_train, \n",
        "            epochs=N_EPOCH, \n",
        "            validation_data =X_val, \n",
        "            verbose=1,\n",
        "            callbacks=callbacks,\n",
        "        )\n",
        "            \n",
        "        return history\n",
        "    \n",
        "    def evaluate_model(self, X_test):\n",
        "        return self.model.evaluate(X_test)\n",
        "        \n",
        "        \n",
        "    def get_model(self):\n",
        "        return self.model\n",
        "    \n",
        "    def save_model(self, model_folder):\n",
        "        \n",
        "        run_model = tf.function(lambda x: self.model(x))\n",
        "        concrete_func = run_model.get_concrete_function(tf.TensorSpec([1, 6, 2], tf.float32))\n",
        "        self.model.save(model_folder, signatures=concrete_func)\n",
        "        print(f'Model {self.model_name} saved at {model_folder}')\n",
        "\n",
        "    def prune_model(self, pruned_model_dir, weights_only = True):\n",
        "        \n",
        "        if not os.path.isdir(pruned_model_dir):\n",
        "            os.makedirs(pruned_model_dir)\n",
        "\n",
        "        self.model = tfmot.sparsity.keras.strip_pruning(self.model)\n",
        "        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
        "        if weights_only:\n",
        "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        tflite_model = converter.convert()\n",
        "        with open(pruned_model_dir +'/saved_model.tflite', 'wb') as fp:\n",
        "            tflite_compressed = zlib.compress(tflite_model) \n",
        "            fp.write(tflite_compressed)\n",
        "\n",
        "        size_model = compute_size(pruned_model_dir)\n",
        "        print(f'Size of the tflite {self.model_name}: {size_model} KB')\n",
        "\n",
        "\n",
        "    \n",
        "    def convert_to(self, model_folder, tflite=True, weights_only=True, weights_activation=True):\n",
        "        \n",
        "        #print(f'From {model_folder} to {tflite_model_dir}')\n",
        "        size_original_model = compute_size(model_folder)\n",
        "        print(f'Size of the original {self.model_name}: {size_original_model} KB')\n",
        "        \n",
        "        \n",
        "        if tflite:  \n",
        "\n",
        "            tflite_model_dir = os.path.join(\"./tflite_models\", self.model_name)\n",
        "            if not os.path.isdir(tflite_model_dir):\n",
        "                os.makedirs(tflite_model_dir)\n",
        "            # --------- with tflite conversion\n",
        "            converter = tf.lite.TFLiteConverter.from_saved_model(model_folder)\n",
        "            # convert the model into a tflite version\n",
        "            tflite_model = converter.convert()\n",
        "            # stored in tflite_model_dir\n",
        "\n",
        "\n",
        "            with open(tflite_model_dir+'/saved_model.tflite', 'wb') as fp: \n",
        "                fp.write(tflite_model)\n",
        "\n",
        "            size_tflite_model = compute_size(tflite_model_dir)\n",
        "            print(f'Size of the tflite {self.model_name}: {size_tflite_model} KB')\n",
        "\n",
        "        if weights_only:\n",
        "            \n",
        "            qtflite_model_dir = os.path.join(\"./weight_only_PTQ_models\", self.model_name)\n",
        "            if not os.path.isdir(qtflite_model_dir):\n",
        "                os.makedirs(qtflite_model_dir)\n",
        "            \n",
        "            # --------- with tflite quantization weight only\n",
        "            converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
        "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "            # convert the model into a tflite version\n",
        "            tflite_model = converter.convert()\n",
        "\n",
        "            with open(qtflite_model_dir + '/saved_model.tflite', 'wb') as fp:\n",
        "                fp.write(tflite_model)\n",
        "\n",
        "            size_qtflite_model = compute_size(qtflite_model_dir)\n",
        "            print(f'Size of the weight only quantization model {self.model_name}: {size_qtflite_model} KB')\n",
        "\n",
        "        \n",
        "        if weights_activation and not (self.model_name=='lstm' or self.model_name=='cnn') :\n",
        "            \n",
        "            qatflite_model_dir = os.path.join(\"./weight_activation_PTQ_models\", self.model_name)\n",
        "            if not os.path.isdir(qatflite_model_dir):\n",
        "                os.makedirs(qatflite_model_dir)\n",
        "\n",
        "            # ---------  with tflite quantization weight and activation\n",
        "            converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
        "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "            converter.representative_dataset = representative_dataset_gen\n",
        "\n",
        "            # to force it to use only int8 ops, as well as int8 inputs and outputs\n",
        "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "            converter.inference_input_type = tf.uint8\n",
        "            converter.inference_output_type = tf.uint8\n",
        "            # convert the model into a tflite version\n",
        "            tflite_model = converter.convert()\n",
        "\n",
        "            with open(qatflite_model_dir + '/saved_model.tflite', 'wb') as fp:\n",
        "                fp.write(tflite_model)\n",
        "\n",
        "            size_aqtflite_model = compute_size(qatflite_model_dir)\n",
        "            print(f'Size of the weight and activation quantization model  {self.model_name}: {size_aqtflite_model} KB')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me7DfgV0mPS5"
      },
      "source": [
        "class CustomMAE(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='CustomMAE', **kwargs):\n",
        "        super(CustomMAE, self).__init__(name=name, **kwargs)\n",
        "        self.sum = self.add_weight(shape=[2], name='sum', initializer='zeros')\n",
        "        self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # accumulate at each batch\n",
        "        values = tf.cast(tf.abs(y_true - y_pred), dtype=tf.float32)\n",
        "        \n",
        "        self.sum.assign_add(tf.reduce_mean(values, axis=[0, 1]))\n",
        "        self.count.assign_add(1)\n",
        "\n",
        "    def result(self):\n",
        "        return tf.math.divide_no_nan(self.sum, self.count)\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.sum.assign(tf.zeros_like(self.sum))\n",
        "        self.count.assign(tf.zeros_like(self.count))\n",
        "\n",
        "\n",
        "def compute_size(path_to_explore):\n",
        "    size = 0\n",
        "    for path in list(os.walk(path_to_explore)):\n",
        "        \n",
        "        root = path[0]\n",
        "        files = path[2]\n",
        "        for file in files:\n",
        "            size += os.path.getsize(root + \"/\" + file)\n",
        "        \n",
        "    return round(size/1024, 3)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RgqvbpghE5i",
        "outputId": "ffdf462f-cf95-442d-c944-6cd1add5167c"
      },
      "source": [
        "N_EPOCH = 70\n",
        "LR = 0.1\n",
        "STEP_SCHEDULER = 7\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  milestone = [10, 30, 60]\n",
        "  if epoch in milestone:\n",
        "    return lr*0.1\n",
        "  else:\n",
        "    return lr \n",
        "\n",
        "eval_metric = [CustomMAE()]\n",
        "loss_function = [tf.keras.losses.MeanSquaredError()]\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "\n",
        "for model_name in ['mlp']:\n",
        "    alpha = 0.3\n",
        "    final_sparsity = 0.90\n",
        "    # model_name, alpha, input_shape, output_shape, final_sparsity\n",
        "    model = MyModel(model_name, alpha, input_shape, output_shape, final_sparsity)\n",
        "    model.compile_model(optimizer, loss_function, eval_metric)\n",
        "    history = model.train_model(train_ds, val_ds, N_EPOCH, callbacks=[tf.keras.callbacks.LearningRateScheduler(scheduler)])\n",
        "\n",
        "    [test_loss, test_mae] = model.evaluate_model(test_ds)\n",
        "    print(test_mae)\n",
        "    model_dir = f'./models/{model.model_name}'\n",
        "    model.save_model(model_dir)\n",
        "    #model.convert_to(model_dir, tflite=False, weights_only=False, weights_activation=False)\n",
        "\n",
        "    # magnitude based pruning\n",
        "    pruned_model_dir = f'./pruned_models/{model.model_name}'\n",
        "    model.prune_model(pruned_model_dir)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "first_dense (Dense)          (None, 38)                494       \n",
            "_________________________________________________________________\n",
            "third_dense (Dense)          (None, 12)                468       \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 6, 2)              0         \n",
            "=================================================================\n",
            "Total params: 962\n",
            "Trainable params: 962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:220: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "\tTraining... \n",
            "\tEpoch 1/70\n",
            "575/575 [==============================] - 16s 28ms/step - loss: 101.8372 - CustomMAE: 4.5244 - val_loss: 5.8693 - val_CustomMAE: 1.5214\n",
            "Epoch 2/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 14.9553 - CustomMAE: 2.3987 - val_loss: 13.4107 - val_CustomMAE: 2.3407\n",
            "Epoch 3/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 44.4552 - CustomMAE: 3.7811 - val_loss: 5.5995 - val_CustomMAE: 1.3696\n",
            "Epoch 4/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 6.9306 - CustomMAE: 1.6160 - val_loss: 14.7255 - val_CustomMAE: 3.0395\n",
            "Epoch 5/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 22.2706 - CustomMAE: 2.5248 - val_loss: 4.6781 - val_CustomMAE: 1.1986\n",
            "Epoch 6/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.7234 - CustomMAE: 1.2532 - val_loss: 4.7110 - val_CustomMAE: 1.2383\n",
            "Epoch 7/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 6.6616 - CustomMAE: 1.5641 - val_loss: 4.9503 - val_CustomMAE: 1.3634\n",
            "Epoch 8/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.8807 - CustomMAE: 1.3193 - val_loss: 7.1015 - val_CustomMAE: 1.6858\n",
            "Epoch 9/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 7.4791 - CustomMAE: 1.6728 - val_loss: 5.0641 - val_CustomMAE: 1.2434\n",
            "Epoch 10/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 6.4267 - CustomMAE: 1.5602 - val_loss: 4.4236 - val_CustomMAE: 1.1768\n",
            "Epoch 11/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.3918 - CustomMAE: 1.1492 - val_loss: 4.1371 - val_CustomMAE: 1.0681\n",
            "Epoch 12/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.4786 - CustomMAE: 1.1837 - val_loss: 4.3576 - val_CustomMAE: 1.1780\n",
            "Epoch 13/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 5.4045 - CustomMAE: 1.3177 - val_loss: 5.2026 - val_CustomMAE: 1.3036\n",
            "Epoch 14/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 5.4447 - CustomMAE: 1.3689 - val_loss: 4.4150 - val_CustomMAE: 1.1564\n",
            "Epoch 15/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.7577 - CustomMAE: 1.2257 - val_loss: 4.2563 - val_CustomMAE: 1.1065\n",
            "Epoch 16/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.5668 - CustomMAE: 1.1853 - val_loss: 4.1723 - val_CustomMAE: 1.0864\n",
            "Epoch 17/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.4429 - CustomMAE: 1.1590 - val_loss: 4.1431 - val_CustomMAE: 1.0758\n",
            "Epoch 18/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.3578 - CustomMAE: 1.1363 - val_loss: 4.1923 - val_CustomMAE: 1.0988\n",
            "Epoch 19/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.2846 - CustomMAE: 1.1153 - val_loss: 4.1491 - val_CustomMAE: 1.0492\n",
            "Epoch 20/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.2285 - CustomMAE: 1.1009 - val_loss: 4.1073 - val_CustomMAE: 1.0867\n",
            "Epoch 21/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.2020 - CustomMAE: 1.0939 - val_loss: 4.0932 - val_CustomMAE: 1.0337\n",
            "Epoch 22/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.1715 - CustomMAE: 1.0865 - val_loss: 4.0343 - val_CustomMAE: 1.0218\n",
            "Epoch 23/70\n",
            "575/575 [==============================] - 3s 5ms/step - loss: 4.1428 - CustomMAE: 1.0796 - val_loss: 4.1752 - val_CustomMAE: 1.1113\n",
            "Epoch 24/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.1358 - CustomMAE: 1.0804 - val_loss: 4.0226 - val_CustomMAE: 1.0320\n",
            "Epoch 25/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.1237 - CustomMAE: 1.0771 - val_loss: 3.9974 - val_CustomMAE: 1.0139\n",
            "Epoch 26/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.1207 - CustomMAE: 1.0738 - val_loss: 4.0550 - val_CustomMAE: 1.0286\n",
            "Epoch 27/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.1008 - CustomMAE: 1.0678 - val_loss: 3.9915 - val_CustomMAE: 1.0207\n",
            "Epoch 28/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0926 - CustomMAE: 1.0674 - val_loss: 3.9962 - val_CustomMAE: 1.0315\n",
            "Epoch 29/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0821 - CustomMAE: 1.0650 - val_loss: 3.9969 - val_CustomMAE: 1.0201\n",
            "Epoch 30/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0788 - CustomMAE: 1.0640 - val_loss: 3.9902 - val_CustomMAE: 1.0081\n",
            "Epoch 31/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0303 - CustomMAE: 1.0457 - val_loss: 3.9769 - val_CustomMAE: 1.0101\n",
            "Epoch 32/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0296 - CustomMAE: 1.0458 - val_loss: 3.9696 - val_CustomMAE: 1.0038\n",
            "Epoch 33/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0301 - CustomMAE: 1.0459 - val_loss: 3.9695 - val_CustomMAE: 1.0056\n",
            "Epoch 34/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0281 - CustomMAE: 1.0458 - val_loss: 3.9689 - val_CustomMAE: 1.0048\n",
            "Epoch 35/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0286 - CustomMAE: 1.0457 - val_loss: 3.9697 - val_CustomMAE: 1.0071\n",
            "Epoch 36/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0280 - CustomMAE: 1.0459 - val_loss: 3.9730 - val_CustomMAE: 1.0010\n",
            "Epoch 37/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0276 - CustomMAE: 1.0448 - val_loss: 3.9756 - val_CustomMAE: 1.0108\n",
            "Epoch 38/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0262 - CustomMAE: 1.0453 - val_loss: 3.9684 - val_CustomMAE: 1.0043\n",
            "Epoch 39/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0257 - CustomMAE: 1.0449 - val_loss: 3.9814 - val_CustomMAE: 1.0112\n",
            "Epoch 40/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0261 - CustomMAE: 1.0449 - val_loss: 3.9776 - val_CustomMAE: 1.0067\n",
            "Epoch 41/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0260 - CustomMAE: 1.0444 - val_loss: 3.9708 - val_CustomMAE: 1.0093\n",
            "Epoch 42/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0245 - CustomMAE: 1.0445 - val_loss: 3.9668 - val_CustomMAE: 1.0035\n",
            "Epoch 43/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0238 - CustomMAE: 1.0443 - val_loss: 3.9688 - val_CustomMAE: 1.0055\n",
            "Epoch 44/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0249 - CustomMAE: 1.0444 - val_loss: 3.9695 - val_CustomMAE: 1.0074\n",
            "Epoch 45/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0248 - CustomMAE: 1.0444 - val_loss: 3.9697 - val_CustomMAE: 1.0036\n",
            "Epoch 46/70\n",
            "575/575 [==============================] - 3s 5ms/step - loss: 4.0235 - CustomMAE: 1.0441 - val_loss: 3.9670 - val_CustomMAE: 1.0067\n",
            "Epoch 47/70\n",
            "575/575 [==============================] - 3s 5ms/step - loss: 4.0235 - CustomMAE: 1.0445 - val_loss: 3.9694 - val_CustomMAE: 0.9977\n",
            "Epoch 48/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0225 - CustomMAE: 1.0435 - val_loss: 3.9664 - val_CustomMAE: 1.0055\n",
            "Epoch 49/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0224 - CustomMAE: 1.0435 - val_loss: 3.9722 - val_CustomMAE: 1.0071\n",
            "Epoch 50/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0209 - CustomMAE: 1.0436 - val_loss: 3.9667 - val_CustomMAE: 1.0042\n",
            "Epoch 51/70\n",
            "575/575 [==============================] - 2s 4ms/step - loss: 4.0214 - CustomMAE: 1.0429 - val_loss: 3.9713 - val_CustomMAE: 1.0135\n",
            "Epoch 52/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0218 - CustomMAE: 1.0437 - val_loss: 3.9690 - val_CustomMAE: 1.0000\n",
            "Epoch 53/70\n",
            "575/575 [==============================] - 3s 4ms/step - loss: 4.0213 - CustomMAE: 1.0431 - val_loss: 3.9653 - val_CustomMAE: 1.0021\n",
            "Epoch 54/70\n",
            "186/575 [========>.....................] - ETA: 1s - loss: 4.2412 - CustomMAE: 1.0716"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dKG4zY3MKOW"
      },
      "source": [
        "from tensorflow import lite as tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwbqQH-MRGXX"
      },
      "source": [
        "with open(pruned_model_dir+'/saved_model.tflite', 'rb') as fp:\n",
        "    model_zip = zlib.decompress(fp.read())\n",
        "\n",
        "    interpreter = tflite.Interpreter(model_content=model_zip)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    accuracy = CustomMAE()\n",
        "    \n",
        "    for length, (x, y) in enumerate(test_ds.unbatch().batch(1)):\n",
        "        \n",
        "        interpreter.set_tensor(input_details[0]['index'], x)\n",
        "        interpreter.invoke()\n",
        "        y_pred = interpreter.get_tensor(output_details[0]['index'])\n",
        "        accuracy.update_state(y, y_pred)\n",
        "print(accuracy.result().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}